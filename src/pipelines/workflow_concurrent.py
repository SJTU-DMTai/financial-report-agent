# -*- coding: utf-8 -*-
from __future__ import annotations

import asyncio
import os
import time
import json
import pickle
import re
import sys
from dataclasses import asdict
from datetime import datetime
from functools import partial
from pathlib import Path

from agentscope.agent import ReActAgent
from agentscope.message import Msg

from evaluation.eval_content import evaluate_segment
from pipelines.planning import process_pdf_to_outline
from src.memory.working import Section, Segment
from src.prompt import prompt_dict
from src.utils.instance import create_chat_model, create_agent_formatter
from src.memory.short_term import ShortTermMemoryStore
from src.memory.long_term import LongTermMemoryStore
from src.agents.searcher import create_searcher_agent, build_searcher_toolkit
from src.agents.writer import create_writer_agent, build_writer_toolkit
from src.agents.planner import create_planner_agent, build_planner_toolkit
from src.agents.verifier import create_verifier_agent, build_verifier_toolkit

from src.utils.file_converter import md_to_pdf, pdf_to_markdown, section_to_markdown
from src.utils.parse_verdict import parse_verifier_verdict
from src.utils.call_with_retry import call_agent_with_retry
from src.utils.get_entity_info import get_entity_info
from src.utils.file_converter import markdown_to_sections
from src.utils.local_file import STOCK_REPORT_PATHS
import config
import asyncio

from src.utils.call_with_retry import call_chatbot_with_retry
from src.utils.instance import llm_reasoning, llm_instruct, formatter, cfg

CURRENT_RUNNING_TASKS = 0

async def search_evidence(evidence, task_desc, segment_topic, searcher):
    searcher_input = Msg(
        name="user",
        content=(
            f"ä»»åŠ¡ï¼š{task_desc}\n"
            f"å½“å‰éœ€è¦ä½ æ’°å†™è¦ç‚¹ï¼š{segment_topic}\n"
            f"è®ºæ®æ‰€éœ€ææ–™ï¼š\n{evidence}\n\n"
            f"è¯·ä½ è°ƒç”¨å·¥å…·æœç´¢ï¼Œå°½é‡æ ¹æ®å¤šä¸ªä¿¡æ¯æºäº¤å‰éªŒè¯åç»™å‡ºæœç´¢ç»“æœã€‚"
        ),
        role="user",
    )
    msg = await call_agent_with_retry(searcher, searcher_input)
    print(f"[Searcher] Finished searching: {evidence[:20]}...")
    return msg.get_text_content()

async def process_single_segment(segment, task_desc, agent_factory, semaphore):
    """å¹¶å‘å¤„ç†å•ä¸ª Segmentï¼šåŒ…å«æœç´¢å’Œå†™ä½œ"""
    global CURRENT_RUNNING_TASKS
    async with semaphore:
        CURRENT_RUNNING_TASKS += 1
        print(f"[{time.strftime('%H:%M:%S')}] [å¹¶å‘æ•°: {CURRENT_RUNNING_TASKS}] âœï¸ å¼€å§‹å†™ä½œ: {segment.topic[:15]}...", flush=True)

        searcher, writer = agent_factory()
        for i, evidence in enumerate(segment.evidences):
            segment.evidences[i] = await search_evidence(evidence, task_desc, segment.topic, searcher)
            await searcher.memory.clear()

        try:
            writer_input = Msg(
                name="user",
                content=(
                    f"ä»»åŠ¡ï¼š{task_desc}\n"
                    f"å½“å‰æ­¥éª¤éœ€è¦ä½ æ’°å†™è¦ç‚¹ï¼š\n{segment.topic}\n"
                    f"å‚è€ƒç¤ºä¾‹ã€å†™ä½œè¦æ±‚å’Œç›¸å…³ææ–™å¦‚ä¸‹ï¼š\n\n{str(segment)}\n\n"
                    f"è¯·ä½ å¼€å§‹æœç´¢å’Œæ’°å†™ã€‚"
                ),
                role="user",
            )

            draft_msg = await call_agent_with_retry(writer, writer_input)
            segment.content = draft_msg.get_text_content()
            print(f"[Writer] Segment finished: {segment.topic}")
            print("[Writer åˆç¨¿è¾“å‡º]")
            print(segment.content, flush=True)

            for _ in range(5):
                segment_score, suggestions = await evaluate_segment(create_chat_model(reasoning=False), 
                                                                    create_agent_formatter(), 
                                                                    segment)
                print("ä¿®æ”¹å»ºè®®:", suggestions, flush=True)
                if suggestions is None:
                    break
                else:
                    writer_input = Msg(
                        name="user", content=f"ç»è¯„ä¼°ï¼š\n{suggestions}\nè¯·ä½ ç»§ç»­ä¿®æ”¹ã€‚", role="user",
                    )
                    draft_msg = await call_agent_with_retry(writer, writer_input)
                    segment.content = draft_msg.get_text_content()
                    print(f"[Writer] Segment finished: {segment.topic}")
                    print(segment.content, flush=True)
            await writer.memory.clear()
            segment.finished = True
        finally:
            CURRENT_RUNNING_TASKS -= 1
            print(f"[{time.strftime('%H:%M:%S')}] [å¹¶å‘æ•°: {CURRENT_RUNNING_TASKS}] âœ… å®Œæˆå†™ä½œ: {segment.topic[:15]}.", flush=True)

async def process_section_concurrently(section: Section, parent_id, task_desc, agent_factory,
                                       semaphore, stock_symbol, output_pth, manuscript_root):
    """é€’å½’å¹¶å‘å¤„ç†ç« èŠ‚"""

    # 1. å¤„ç†å­ç« èŠ‚ (é€’å½’) - ä¼˜å…ˆå¯åŠ¨å­ä»»åŠ¡
    sub_tasks = []
    if section.subsections:
        for subsection in section.subsections:
            section_id = ((parent_id + ".") if parent_id else "") + str(subsection.section_id)
            # é€’å½’è°ƒç”¨
            sub_tasks.append(process_section_concurrently(
                subsection, section_id, task_desc, agent_factory, semaphore, stock_symbol,
                output_pth, manuscript_root
            ))

    # 2. å¤„ç†å½“å‰ç« èŠ‚çš„ Segments (å¹¶å‘)
    seg_tasks = []
    if section.segments:
        print(f"\n====== å¯åŠ¨ç« èŠ‚ Segments å¹¶å‘å¤„ç†: {parent_id} ======\n")
        for segment in section.segments:
            seg_tasks.append(process_single_segment(
                segment, task_desc, agent_factory, semaphore
            ))

    # 3. ç­‰å¾…æ‰€æœ‰ Segments å®Œæˆ
    if seg_tasks:
        await asyncio.gather(*seg_tasks)

        # 4. ç”Ÿæˆæ ‡é¢˜ (Segments å®Œæˆåæ‰èƒ½åšæ€»ç»“)
        # è¿™é‡Œéœ€è¦ä¸€ä¸ªä¸´æ—¶çš„ writer æ¥åšæ€»ç»“
        global CURRENT_RUNNING_TASKS  # å¼•å…¥å…¨å±€å˜é‡
        CURRENT_RUNNING_TASKS += 1
        print(
            f"[{time.strftime('%H:%M:%S')}] [å¹¶å‘æ•°: {CURRENT_RUNNING_TASKS}] ğŸ·ï¸ ç”Ÿæˆæ ‡é¢˜: {section.title[:10]}...", flush=True)

        section_text = "\n".join([s.content for s in section.segments])
        llm_instruct = create_chat_model(reasoning=False)
        formatter = create_agent_formatter()
        def _parse_res(text):
            title = re.search("<title>(.+)</title>", text, re.DOTALL)
            content = re.search("<content>(.+)</content>", text, re.DOTALL)
            assert title is not None and content is not None, "è¾“å‡ºæ ¼å¼ä¸å¯¹ï¼Œç­”æ¡ˆæ²¡æœ‰è¢«åˆé€‚çš„æ ‡ç­¾åŒ…è£¹ä½ã€‚"
            title = title.group(1).strip().strip("#").strip()
            content = content.group(1).strip()
            return title, content
        title, content = await call_chatbot_with_retry(
            llm_instruct, formatter,
            "ä½ æ˜¯æ’°å†™é‡‘èç ”æŠ¥çš„ä¸“å®¶ã€‚æˆ‘å°†æä¾›æŸä¸€ç« èŠ‚åˆç¨¿ï¼Œè¯·ä½ åˆ å»æ— æ„ä¹‰çš„éƒ¨åˆ†ï¼Œè¾“å‡ºæ¶¦è‰²åçš„å†…å®¹ï¼Œä¸è¦ç¯¡æ”¹å…³é”®ä¿¡æ¯ã€‚",
            f"é‡‘èç ”æŠ¥æŸä¸€ç« èŠ‚åˆç¨¿å¦‚ä¸‹ï¼š\n\n{section_text}\n\n"
            f"è¯¥ç« èŠ‚æ˜¯å‚è€ƒäº†å°æ ‡é¢˜ä¸º{section.title}çš„æŸä¸ªèŒƒä¾‹æ’°å†™çš„ï¼Œè¯·ä½ æ ¹æ®åˆç¨¿é‡æ–°èµ·ä¸€ä¸ªæ ‡é¢˜ï¼Œç”¨<title>å’Œ</title>åŒ…è£¹ä½ï¼Œé™åå­—ä»¥å†…ã€‚"
            f"å¹¶åœ¨åˆç¨¿åŸºç¡€ä¸Šç¨ä½œæ¶¦è‰²ï¼Œæ›´æ–°åçš„å†…å®¹ç”¨<content>å’Œ</content>åŒ…è£¹ä½ã€‚",
            _parse_res, handle_hook_exceptions=(AssertionError, )
        )
        section.title = title
        section.content = content
        print(f"[Final section] {section.title}")
        print(section.content)
        CURRENT_RUNNING_TASKS -= 1

    # 5. ç­‰å¾…å­ç« èŠ‚é€’å½’å®Œæˆ (å¦‚æœéœ€è¦ä¸¥æ ¼çš„å±‚çº§é¡ºåºä¿å­˜ï¼Œå¯ä»¥è°ƒæ•´ await ä½ç½®)
    if sub_tasks:
        await asyncio.gather(*sub_tasks)

    # 6. ä¿å­˜ä¸­é—´ç»“æœ (å¯é€‰ï¼Œé˜²æ­¢å´©æºƒå…¨ä¸¢)
    # æ³¨æ„ï¼šå¹¶å‘å†™å…¥æ–‡ä»¶å¯èƒ½å†²çªï¼Œè¿™é‡Œç®€å•å¤„ç†ï¼Œå®é™…ç”Ÿäº§å»ºè®®ç”¨å•ç‹¬çš„ save åç¨‹æˆ–é”
    (output_pth / f"{stock_symbol}_{os.getenv("CUR_DATE", datetime.today().strftime("%Y-%m-%d"))}.json").write_text(manuscript_root.to_json(ensure_ascii=False))


async def run_workflow(task_desc: str):
    """å›´ç»•ä¸€ä¸ª task description æ‰§è¡Œå®Œæ•´çš„ç ”æŠ¥ç”Ÿæˆæµç¨‹ã€‚
    """
    # ----- 1. å‡†å¤‡ memory store -----

    PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent

    long_term_dir = PROJECT_ROOT / "data" / "memory" / "long_term"
    
    long_term = LongTermMemoryStore(
        base_dir=long_term_dir,
    )


    planner_cfg = cfg.get_planner_cfg()
    use_demo = planner_cfg.get("use_demonstration", False)

    entity = get_entity_info(long_term, task_desc)
    if not entity or not entity.get("code"):
        raise ValueError(f"æ— æ³•ä» task_desc è§£æè‚¡ç¥¨å®ä½“/ä»£ç ï¼š{task_desc}")

    stock_symbol = entity["code"]  # çº¯æ•°å­— 6 ä½ä»£ç 
    print("è‚¡ç¥¨ä»£ç ï¼š", stock_symbol)

    filename = f"{stock_symbol}_{os.getenv("CUR_DATE", datetime.today().strftime("%Y-%m-%d"))}"
    short_term_dir = PROJECT_ROOT / "data" / "memory" / "short_term" / filename

    short_term = ShortTermMemoryStore(
        base_dir=short_term_dir,
    )

    # è§£ædemonstration reportï¼Œç¬¬äºŒéè§£æåŒä¸€ä¸ªreportå¯ä»¥æ³¨é‡Šæ‰
    demo_pdf_path = STOCK_REPORT_PATHS[stock_symbol][-1]
    manuscript = await process_pdf_to_outline(demo_pdf_path, long_term_dir / "demonstration",
                                              llm_reasoning, llm_instruct, formatter,)

    verifier_toolkit = build_verifier_toolkit(
        short_term=short_term,
        long_term=long_term,
    )
    verifier = create_verifier_agent(model=llm_reasoning, formatter=formatter, toolkit=verifier_toolkit)

    output_pth = PROJECT_ROOT / "data" / "output" / "reports"

    # è®¾ç½®å¹¶å‘ä¿¡å·é‡
    CONCURRENCY_LIMIT = int(os.getenv("N_THREAD", 32))
    semaphore = asyncio.Semaphore(CONCURRENCY_LIMIT)

    def create_searcher_writer():
        searcher_toolkit = build_searcher_toolkit(
            short_term=short_term,
            long_term=long_term,
        )
        searcher = create_searcher_agent(model=llm_reasoning, formatter=formatter, toolkit=searcher_toolkit)
        writer_toolkit = build_writer_toolkit(
            short_term=short_term,
            long_term=long_term,
            searcher=searcher,
        )
        writer = create_writer_agent(model=llm_reasoning, formatter=formatter, toolkit=writer_toolkit)
        return searcher, writer

    # å¯åŠ¨é€’å½’å¹¶å‘å¤„ç†
    await process_section_concurrently(
        section=manuscript,
        parent_id=None,
        task_desc=task_desc,
        agent_factory=create_searcher_writer,
        semaphore=semaphore,
        stock_symbol=stock_symbol,
        output_pth=output_pth,
        manuscript_root=manuscript # ç”¨äºåœ¨æ·±å±‚é€’å½’ä¸­ä¿å­˜å®Œæ•´çš„ json
    )

    markdown_text = section_to_markdown(manuscript)
    (output_pth / f"{filename}.md").write_text(markdown_text, encoding="utf-8")
    md_to_pdf(markdown_text, short_term=short_term, output_dir=output_pth / f"{filename}.pdf")
